{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8553dde0",
   "metadata": {},
   "source": [
    "## 00. PyTorch Fundamentals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bce69bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Aug  9 18:04:00 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.64.03              Driver Version: 575.64.03      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...    Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   35C    P0             12W /   55W |      11MiB /   8188MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1483      G   /usr/lib/xorg/Xorg                        4MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc13ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.1+cu117\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3655c308",
   "metadata": {},
   "source": [
    "## Introduction to tensors "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70898af7",
   "metadata": {},
   "source": [
    "### Creating tensors \n",
    "\n",
    "PyTorch tensors are created by using torch.Tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af21d07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar (escalar de toda la vida)\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc81f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim # Number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e840843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as Python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e3c20cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector \n",
    "vector = torch.tensor([7, 7])\n",
    "vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d97445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim # (lo mismo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d797b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape # (Numero de elementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83195032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "MATRIX = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "MATRIX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abc19ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim # (Dimensiones = nÂº de \"caminos\" por los que se puede ir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0810a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape # (Dos elementos donde cada uno contiene dos sub-elementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a12c2713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3,  7],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 7,  8,  9,  7]],\n",
       "\n",
       "        [[10, 11, 12,  7],\n",
       "         [13, 14, 15,  7],\n",
       "         [16, 17, 18,  7]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "TENSOR = torch.tensor([[[1,2,3,7],\n",
    "                        [4,5,6,7],\n",
    "                        [7,8,9,7]],\n",
    "                       \n",
    "                       [[10,11,12,7],\n",
    "                        [13,14,15,7],\n",
    "                        [16,17,18,7]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17d01819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a8440e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128c3757",
   "metadata": {},
   "source": [
    "### Random tensors \n",
    "\n",
    "Why random tensors? \n",
    "\n",
    "NN start with random weights (random tensors) -> look at data -> update -> look data -> (...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ccdc56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4839, 0.7987, 0.5119, 0.6049],\n",
       "         [0.0308, 0.5944, 0.4052, 0.8905],\n",
       "         [0.4375, 0.1705, 0.0639, 0.1402]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(1, 3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec4f6c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim # (Matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caa03c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape # (3 filas, 4 columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06b59cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([224, 224, 3]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random tensor with similar shape to an image\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
    "random_image_size_tensor.ndim, random_image_size_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2dab8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5.1095e-01, 9.7253e-01, 1.6662e-01],\n",
       "         [9.5364e-01, 8.6247e-01, 3.5689e-01],\n",
       "         [6.2320e-01, 5.7783e-01, 6.4441e-01],\n",
       "         ...,\n",
       "         [3.2731e-01, 2.3088e-01, 1.7486e-02],\n",
       "         [3.1804e-02, 8.5454e-01, 5.4096e-02],\n",
       "         [8.2227e-01, 4.6879e-01, 3.9290e-01]],\n",
       "\n",
       "        [[7.0304e-04, 7.3104e-01, 5.2357e-01],\n",
       "         [1.0409e-02, 3.2124e-01, 6.1057e-01],\n",
       "         [2.9702e-01, 5.5370e-01, 7.8685e-01],\n",
       "         ...,\n",
       "         [7.3054e-01, 1.2961e-01, 9.9554e-01],\n",
       "         [2.2757e-01, 3.4823e-01, 4.2604e-02],\n",
       "         [5.7891e-01, 2.1139e-01, 7.8240e-01]],\n",
       "\n",
       "        [[1.1037e-01, 7.4539e-01, 7.9907e-01],\n",
       "         [4.5550e-01, 5.9809e-01, 3.8981e-01],\n",
       "         [9.8910e-01, 1.2288e-01, 9.2086e-01],\n",
       "         ...,\n",
       "         [8.1954e-01, 2.5988e-01, 2.2851e-01],\n",
       "         [5.0477e-01, 1.3430e-01, 1.8047e-01],\n",
       "         [9.8147e-01, 6.5147e-01, 9.5450e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[9.4460e-01, 8.9026e-01, 7.1514e-01],\n",
       "         [6.7985e-01, 2.3493e-01, 6.0330e-01],\n",
       "         [2.2530e-02, 6.8740e-01, 3.2394e-01],\n",
       "         ...,\n",
       "         [5.4027e-01, 8.8354e-01, 9.4288e-01],\n",
       "         [5.9405e-01, 9.4012e-01, 8.3135e-01],\n",
       "         [2.9468e-01, 9.1380e-01, 2.7467e-01]],\n",
       "\n",
       "        [[4.8989e-01, 9.2924e-01, 6.1237e-01],\n",
       "         [6.3433e-01, 6.3285e-01, 4.4341e-01],\n",
       "         [1.5004e-01, 4.0232e-01, 5.4973e-01],\n",
       "         ...,\n",
       "         [1.2195e-04, 8.5960e-01, 8.4248e-01],\n",
       "         [9.0448e-01, 3.7426e-01, 3.5533e-02],\n",
       "         [5.9857e-01, 6.5725e-01, 3.4131e-01]],\n",
       "\n",
       "        [[1.4596e-01, 3.7578e-01, 9.3192e-01],\n",
       "         [3.7501e-01, 6.8559e-01, 6.4656e-01],\n",
       "         [9.0554e-02, 3.7893e-01, 1.1817e-02],\n",
       "         ...,\n",
       "         [3.5328e-01, 5.0260e-01, 9.8458e-01],\n",
       "         [3.9603e-01, 8.3349e-01, 8.0914e-01],\n",
       "         [3.7193e-01, 5.7773e-01, 2.9784e-01]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05288a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c32b34d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros * random_tensor # Element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc8ef43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size=(3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bebf7a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab2ef7a",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86abce15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(start=1, end=11, step=1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b1d2e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors like \n",
    "ten_zeros = torch.zeros_like(input=one_to_ten) \n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e061458",
   "metadata": {},
   "source": [
    "### Tensor Datatypes\n",
    "\n",
    "**NOTE**: Tensor datatypes are one of the big three issues with PyTorch & Deep learning:\n",
    "    1. Tensors not right datatype\n",
    "    2. Tensors not right shape \n",
    "    3. Tensors not right device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fcec5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # What data type is the tensor (float32, float16,...)\n",
    "                               device=None, # What device is the tensor on (CPU, GPU)\n",
    "                               requires_grad=False) # Whetther or not to track gradients with this tensor\n",
    "\n",
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ca68371",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16) # Changes tensor datatype to another "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e02e11bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor # Works, but not all operations works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3621ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.long)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "794dde9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor * float_32_tensor # Works, but not all operations works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eb1108",
   "metadata": {},
   "source": [
    "### Getting information from tensors (tensor attributes)\n",
    "\n",
    "1. Tensors not right datatype -> 'tensor.dtype'\n",
    "2. Tensors not right shape -> 'tensor.shape'\n",
    "3. Tensors not right device -> 'tensor.device'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcf1b598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4504, 0.7138, 0.3849, 0.1087],\n",
       "        [0.3452, 0.6753, 0.0976, 0.2769],\n",
       "        [0.3381, 0.6993, 0.7619, 0.1506]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor \n",
    "some_tensor = torch.rand(size=(3, 4))\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96ab2f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some tensor: \n",
      "tensor([[0.4504, 0.7138, 0.3849, 0.1087],\n",
      "        [0.3452, 0.6753, 0.0976, 0.2769],\n",
      "        [0.3381, 0.6993, 0.7619, 0.1506]])\n",
      "- Datatype of tensor: torch.float32\n",
      "- Shape of tensor: torch.Size([3, 4])\n",
      "- Device tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"Some tensor: \\n{some_tensor}\")\n",
    "print(f\"- Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"- Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"- Device tensor is on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23147f2d",
   "metadata": {},
   "source": [
    "### Manipulating tensors \n",
    "\n",
    "Tensors operations:\n",
    "1. Addition\n",
    "2. Subtraction \n",
    "3. Multiplication (elemento-wise)\n",
    "4. Division \n",
    "5. Matrix multiplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0264cb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor \n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fffbfef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([51, 52, 53]), tensor([-49, -48, -47]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Addition and subtraction\n",
    "tensor + 50, tensor - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc76adf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication tensor \n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c4cba94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10, 20, 30]), tensor([51, 52, 53]), tensor([-49, -48, -47]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out pytorch in-built functions (se pueden utilizar las anteriores directamente, mas entendibles)\n",
    "torch.mul(tensor, 10), torch.add(tensor, 50), torch.sub(tensor, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9ad7c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3]) = tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "### Matrix multiplications: element-wise \n",
    "print(f\"{tensor} * {tensor} = {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4a8b3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) @ tensor([1, 2, 3]).T = 14\n",
      "tensor([1, 2, 3]) @ tensor([1, 2, 3]).T = 14\n",
      "tensor([1, 2, 3]) @ tensor([1, 2, 3]).T = 14\n"
     ]
    }
   ],
   "source": [
    "### Matrix multiplications: dot product\n",
    "## Option 1: @ operator \n",
    "print(f\"{tensor} @ {tensor}.T = {tensor @ tensor.T}\")\n",
    "\n",
    "# Option 2: torch.matmul function \n",
    "print(f\"{tensor} @ {tensor}.T = {torch.matmul(tensor, tensor.T)}\")\n",
    "\n",
    "# Option 3: by hand \n",
    "print(f\"{tensor} @ {tensor}.T = {tensor[0]*tensor[0] + tensor[1]*tensor[1] + tensor[2]*tensor[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3dabb43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: 14\n",
      "Time taken: 2.236604690551758 milliseconds\n",
      "Value: 14\n",
      "Time taken: 0.6434917449951172 milliseconds\n"
     ]
    }
   ],
   "source": [
    "# Time comparations \n",
    "# By hand \n",
    "import time \n",
    "start = time.time()\n",
    "\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "end = time.time()\n",
    "print(f\"Value: {value}\")\n",
    "print(f\"Time taken: {(end - start)*1000} milliseconds\")\n",
    "\n",
    "start = time.time()\n",
    "value = torch.matmul(tensor, tensor)\n",
    "end = time.time()\n",
    "print(f\"Value: {value}\")\n",
    "print(f\"Time taken: {(end - start)*1000} milliseconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfe5f0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1033.468246459961 milliseconds\n",
      "Time taken: 1042.6099300384521 milliseconds\n"
     ]
    }
   ],
   "source": [
    "# Now trying with a larger tensor \n",
    "tensor2 = torch.rand(size=(1000, 1000), dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "start = time.time()\n",
    "value = torch.matmul(tensor2, tensor2)\n",
    "end = time.time()\n",
    "print(f\"Time taken: {(end - start)*1000} milliseconds\")\n",
    "\n",
    "value = 0\n",
    "for i in range(len(tensor2)):\n",
    "    value += tensor2[i] * tensor2[i]\n",
    "end = time.time()\n",
    "print(f\"Time taken: {(end - start)*1000} milliseconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6529646",
   "metadata": {},
   "source": [
    "### One of most common errors in deep learning: shape errors\n",
    "\n",
    "In matrix multiplication, two main rules: <br>\n",
    "1. **Inner dimensions** must match : (3,2,1) @ (1,5,7) @ (7,2,5) ...<br>\n",
    "2. The resulting matrix has the shape of the **outer dimensions**: (2,3) @ (3,7) -> (2,7)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9286f73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplication tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n",
      "Shapes: \n",
      "A: torch.Size([3, 2])\n",
      "B.T: torch.Size([2, 3])\n",
      "\n",
      "Inners dimensions match!\n",
      "\n",
      "New shape: torch.Size([3, 3]) -> New shape match with outter dimensions!\n"
     ]
    }
   ],
   "source": [
    "# Shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                        [3,4],\n",
    "                        [5,6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                        [8,11],\n",
    "                        [9,12]])\n",
    "\n",
    "print(f\"Multiplication {torch.mm(tensor_A, tensor_B.T)}\") # torch.matmult = toch.mm\n",
    "print(f\"Shapes: \\nA: {tensor_A.shape}\\nB.T: {tensor_A.T.shape}\\n\\nInners dimensions match!\")\n",
    "print(f\"\\nNew shape: {torch.mm(tensor_A, tensor_B.T).shape} -> New shape match with outter dimensions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7259fcf5",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum, etc (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14b6e916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor \n",
    "x = torch.arange(0,100,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "691e5d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  tensor(0) tensor(0)\n",
      "Max:  tensor(90) tensor(90)\n"
     ]
    }
   ],
   "source": [
    "# Find min \n",
    "print(\"Min: \",torch.min(x), x.min()) # Same output, one it's a function and the other a class method \n",
    "\n",
    "# Find max \n",
    "print(\"Max: \",torch.max(x), x.max()) # '' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30290618",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Find average\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m## Error: wrong data type .type\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "# Find average\n",
    "print(\"Mean:\", torch.mean(x)) ## Error: wrong data type .type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "132b8003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype # Ints do not work with mean, in CUDA mean operations are optimized for float data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfbcb8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor(45.)\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean:\", torch.mean(x.type(torch.float32))) # Corrected data type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d98a3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find sum \n",
    "torch.sum(x), x.sum() # Same output, one it's a function and the other a class method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0110a685",
   "metadata": {},
   "source": [
    "### Finding positional min and max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81acfe9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b8d5848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(9))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmin(), x.argmax() # -> Returns the index of the min/max value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c5fb221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.min() == x[x.argmin()] # Same "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41578ec",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping: repshapes an input tensor to a defined shape.\n",
    "* View: return a view of an input tensor of a certain shape but keep the same memory as the original tensor.\n",
    "* Stacking: combine multiple tensors on top of each other (vstack) or side by side.\n",
    "* Squeeze: removes all `1`dimensions from a tensor.\n",
    "* Unsqueeze: adds a `1`dimensions from a tensor.\n",
    "* Permute: Return a view of the input tensor with dimensions permuted (swapped) in a certain way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38d58a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.Size([10]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a tesnor \n",
    "x2 = torch.arange(1., 11.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e81fbdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape: Add and extra dimension \n",
    "#x2_reshaped = x2.reshape(1,7) # Do not work\n",
    "#x2_reshaped, x2_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56baca65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape: Add and extra dimension \n",
    "x2_reshaped = x2.reshape(1,10) # Do work, but actually don't change the data\n",
    "x2_reshaped, x2_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b4108f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.],\n",
       "         [ 2.],\n",
       "         [ 3.],\n",
       "         [ 4.],\n",
       "         [ 5.],\n",
       "         [ 6.],\n",
       "         [ 7.],\n",
       "         [ 8.],\n",
       "         [ 9.],\n",
       "         [10.]]),\n",
       " torch.Size([10, 1]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape: Add and extra dimension \n",
    "x2_reshaped = x2.reshape(10,1) # Do work: we basically transpose the tensor  \n",
    "x2_reshaped, x2_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bcc9c7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.,  9., 10.]]),\n",
       " torch.Size([2, 5]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape: Add and extra dimension \n",
    "x2_reshaped = x2.reshape(2,5) # Do work: 2 x 5 = 10, same number of elements as original tensor.  \n",
    "x2_reshaped, x2_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "02553ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]]), torch.Size([1, 10]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change de view: quite similar to reshape, but shares the same memory\n",
    "z = x.view(1, 10)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2bfe1d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([77, 10, 20, 30, 40, 50, 60, 70, 80, 90]) \n",
      "Z: tensor([[77, 10, 20, 30, 40, 50, 60, 70, 80, 90]])\n",
      "It changed!\n"
     ]
    }
   ],
   "source": [
    "# Prove: changing the view changes the original tensor\n",
    "z[:, 0] = 77\n",
    "print(\"X:\",x,\"\\nZ:\" ,z)\n",
    "print(\"It changed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "46638dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]), torch.Size([10]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebember x2:\n",
    "x2, x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f9ef1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked at first dimension(0)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
       " torch.Size([4, 10]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other \n",
    "x_stacked = torch.stack([x2, x2, x2, x2], dim=0)\n",
    "print(\"Stacked at first dimension(0)\\n\")\n",
    "\n",
    "x_stacked, x_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5604929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked at second dimension(1)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  1.,  1.,  1.],\n",
       "         [ 2.,  2.,  2.,  2.],\n",
       "         [ 3.,  3.,  3.,  3.],\n",
       "         [ 4.,  4.,  4.,  4.],\n",
       "         [ 5.,  5.,  5.,  5.],\n",
       "         [ 6.,  6.,  6.,  6.],\n",
       "         [ 7.,  7.,  7.,  7.],\n",
       "         [ 8.,  8.,  8.,  8.],\n",
       "         [ 9.,  9.,  9.,  9.],\n",
       "         [10., 10., 10., 10.]]),\n",
       " torch.Size([10, 4]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked2 = torch.stack([x2, x2, x2, x2], dim=1)\n",
    "print(\"Stacked at second dimension(1)\\n\")\n",
    "\n",
    "x_stacked2, x_stacked2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26499e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
      "        [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
      "        [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
      "        [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]) \n",
      " torch.Size([4, 10])\n",
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.,  1.,  2.,  3.,  4.,\n",
      "         5.,  6.,  7.,  8.,  9., 10.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,\n",
      "         9., 10.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]) \n",
      " torch.Size([40])\n"
     ]
    }
   ],
   "source": [
    "# Vstack\n",
    "x_vstacked = torch.vstack([x2,x2,x2,x2])\n",
    "print(x_vstacked,\"\\n\", x_vstacked.shape)\n",
    "\n",
    "# Hstack \n",
    "x_hstacked = torch.hstack([x2,x2,x2,x2])\n",
    "print(x_hstacked,\"\\n\", x_hstacked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7764384d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [3, 4],\n",
       "         [5, 6],\n",
       "         [7, 8]]),\n",
       " torch.Size([4, 2]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1 = torch.tensor([[1,2],\n",
    "                     [3,4]]) # (2,2)\n",
    "\n",
    "tmp2 = torch.tensor([[5,6],\n",
    "                     [7,8]]) # (2,2)\n",
    "\n",
    "tmp3 = torch.vstack((tmp1,tmp2))\n",
    "tmp3, tmp3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "75830c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 5, 6],\n",
       "         [3, 4, 7, 8]]),\n",
       " torch.Size([2, 4]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1 = torch.tensor([[1,2],\n",
    "                     [3,4]]) # (2,2)\n",
    "\n",
    "tmp2 = torch.tensor([[5,6],\n",
    "                     [7,8]]) # (2,2)\n",
    "\n",
    "tmp3 = torch.hstack((tmp1,tmp2))\n",
    "tmp3, tmp3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7781cf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2],\n",
       "          [3, 4]],\n",
       " \n",
       "         [[5, 6],\n",
       "          [7, 8]],\n",
       " \n",
       "         [[5, 6],\n",
       "          [7, 8]]]),\n",
       " torch.Size([3, 2, 2]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1 = torch.tensor([[1,2],[3,4]]) # (2,2)\n",
    "tmp2 = torch.tensor([[5,6],[7,8]]) # (2,2)\n",
    "tmp3 = torch.stack((tmp1,tmp2,tmp2), dim=0) # (2,2,2)\n",
    "\n",
    "tmp3, tmp3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba758b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 9]), tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch squeeze: it eliminates the extra dimensions that are 1\n",
    "# Example: \n",
    "# Original tensor: 1 x 9\n",
    "# After squeeze: 9\n",
    "x_reshaped = torch.tensor([[5,2,3,4,5,6,7,8,9]], dtype=torch.float32) \n",
    "x_reshaped.shape, x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "69c550eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped_squeezed = x_reshaped.squeeze() \n",
    "x_reshaped_squeezed, x_reshaped_squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "37662593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor with extra '1' dimensions: torch.Size([1, 1, 9])\n",
      "After squeeze: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "x_reshaped3 =  torch.tensor([[[5,2,3,4,5,6,7,8,9]]], dtype=torch.float32) \n",
    "print(f\"Tensor with extra '1' dimensions: {x_reshaped3.shape}\\nAfter squeeze: {x_reshaped3.squeeze().shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f83aa3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor torch.Size([9])\n",
      "After unsqueeze at dim 0 torch.Size([1, 9])\n",
      "After unsqueeze at dim 1 torch.Size([9, 1])\n"
     ]
    }
   ],
   "source": [
    "# Torch unsqueeze: adds a single dimension to a target tensor at a specific dim\n",
    "print(f\"Previous tensor {x_reshaped_squeezed.shape}\")\n",
    "print(f\"After unsqueeze at dim 0 {x_reshaped_squeezed.unsqueeze(dim=0).shape}\")\n",
    "print(f\"After unsqueeze at dim 1 {x_reshaped_squeezed.unsqueeze(dim=1).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f56278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: torch.Size([224, 224, 3])\n",
      "Permuted tensor: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Torch permute: rearranges the dimensions of a target tensor in a specific order\n",
    "## Gives a view, so it shares the same memory, it's nota copy.\n",
    "\n",
    "x_original = torch.rand(size=(224,224,3)) # (Height Width Channels)\n",
    "x_original.shape\n",
    "\n",
    "# Permute the original tensor to rearrange the dimensions \n",
    "x_permuted = x_original.permute(2, 0, 1) \n",
    "\n",
    "# Changes: \n",
    "# Original(2) -> Permuted(0)\n",
    "# Original(0) -> Permuted(1)\n",
    "# Original(1) -> Permuted(2)\n",
    "\n",
    "print(f\"Original tensor: {x_original.shape}\")\n",
    "print(f\"Permuted tensor: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9724c23",
   "metadata": {},
   "source": [
    "### Indexing with pytorch (selection data from tensors)\n",
    "Quite similar to NumPy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9cccfeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor \n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9921a346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing first dimension: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Indexion second dimension: \n",
      "tensor([1, 2, 3])\n",
      "Indexing third dimension: \n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index \n",
    "print(f\"Indexing first dimension: \\n{x[0]}\")\n",
    "print(f\"Indexion second dimension: \\n{x[0,0]}\")\n",
    "print(f\"Indexing third dimension: \\n{x[0,0,0]}\")\n",
    "\n",
    "# By the way, x[i][j][k] equals x[i,j,k]\n",
    "# To select all elements in a dimension use \":\"\n",
    "\n",
    "x[0, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f6bca2",
   "metadata": {},
   "source": [
    "## PyTorch and NumPy \n",
    "\n",
    "Because NumPy popularity, PyTorch can interact with certain functions with NumPy \n",
    "\n",
    "* Data in numpy, want in pytorch: `torch.from_numpy(ndarray)`\n",
    "* pytorch tensor -> numpy: `torch.tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea048e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5. 6. 7.] \n",
      " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# NumPy to PyTorch \n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "print(array,\"\\n\",tensor) # dtype is float64 cause it is numpy default data type\n",
    "# However, torch default data type is float32, so be careful -> WRONG DATA TYPE ERROR INCOMING!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a296b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change array value\n",
    "array = array + 1\n",
    "array, tensor\n",
    "\n",
    "# from_numpy make a copy, not shared memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad563f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch to NumPy\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor\n",
    "# Same for dtype, numpy takes the same dtype as the tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "54809f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 3., 3., 3., 3., 3., 3.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor\n",
    "\n",
    "# Do not share memory too"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd28830",
   "metadata": {},
   "source": [
    "## Reproductbility\n",
    "\n",
    "Idea: **Random seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e68935b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5531, 0.6672, 0.0865, 0.8787],\n",
      "        [0.4760, 0.3554, 0.5411, 0.9239],\n",
      "        [0.3883, 0.7602, 0.6547, 0.0512]]) \n",
      " tensor([[0.7901, 0.6230, 0.2371, 0.5763],\n",
      "        [0.7830, 0.0757, 0.9348, 0.7909],\n",
      "        [0.0536, 0.8079, 0.9645, 0.1864]]) \n",
      "\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A,\"\\n\",random_tensor_B,\"\\n\")\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d0a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Let`s make it reproducible \n",
    "RANDOM_SEED = 123\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "print(random_tensor_C == random_tensor_D)\n",
    "\n",
    "# Torch.manual_seed works just once, so if you want to reset the seed, you have to call it again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb98c341",
   "metadata": {},
   "source": [
    "### Running tensors and python objects on GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6e14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check for GPU access wtih PyTorch\n",
    "torch.cuda.is_available() # Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "88a02e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c6ed87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of devices \n",
    "torch.cuda.device_count() #  In my case of course is 1 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4fe151db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# Putting tensors and models on the GPU\n",
    "tensor = torch.tensor([1,2,3], device = \"cpu\")\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120acaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([835632, 0, 3422636128], device='cuda:0')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU is available\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu # With multiple GPUs you will need the cuda:index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "61ad30e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving tensors back to the cpu   \n",
    "tensor_back_cpu = tensor_on_gpu.cpu() # Back to cpu\n",
    "numpy_array =  tensor_back_cpu.numpy() # Into numpy \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch.env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
