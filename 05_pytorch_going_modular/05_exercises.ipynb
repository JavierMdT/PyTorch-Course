{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a86ca4ef",
   "metadata": {},
   "source": [
    "# Exercises & extra-curriculum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9305fb1e",
   "metadata": {},
   "source": [
    "#### 1. Turn the code to get the data (from section 1. Get Data above) into a Python script, such as get_data.py.\n",
    "* When you run the script using python get_data.py it should check if the data already exists and skip downloading if it does.\n",
    "* If the data download is successful, you should be able to access the pizza_steak_sushi images from the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26c4fc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/get_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/get_data.py \n",
    "import os \n",
    "import zipfile \n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "# Create directory if needed\n",
    "data_path = Path(\".data\")\n",
    "if not data_path.is_dir():\n",
    "    print(f\"Creating the '{str(data_path)}' directory...\")\n",
    "    data_path.mkdir(parents=True)\n",
    "else:\n",
    "    print(f\"Directory '{str(data_path)}' already exists, skipping this step.\")\n",
    "\n",
    "# Download the data if needed \n",
    "if not any(data_path.iterdir()): \n",
    "    with open(data_path/\"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        print(f\"Downloading the zip data file...\")\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    # Unzipping data\n",
    "    image_path = data_path/\"pizza_steak_sushi\"\n",
    "    with zipfile.ZipFile(data_path/\"pizza_steak_sushi.zip\") as zip_f:\n",
    "        print(\"Unzipping data...\")\n",
    "        zip_f.extractall(image_path)\n",
    "    print(f\"Removing zipfile...\")\n",
    "    os.remove(data_path/\"pizza_steak_sushi.zip\")\n",
    "else:\n",
    "    print(f\"Data already downloaded, skipping this step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0301eb53",
   "metadata": {},
   "source": [
    "#### 2. Use Python's argparse module to be able to send the train.py custom hyperparameter values for training procedures.\n",
    "1. Add an argument for using a different:\n",
    "    * Training/testing directory\n",
    "    * Learning rate\n",
    "    * Batch size\n",
    "    * Number of epochs to train for\n",
    "    * Number of hidden units in the TinyVGG model\n",
    "2. Keep the default values for each of the above arguments as what they already are (as in notebook 05).\n",
    "3. For example, you should be able to run something similar to the following line to train a TinyVGG model with a learning rate of 0.003 and a batch size of 64 for 20 epochs: python train.py --learning_rate 0.003 --batch_size 64 --num_epochs 20.\n",
    "4. Note: Since train.py leverages the other scripts we created in section 05, such as, model_builder.py, utils.py and engine.py, you'll have to make sure they're available to use too. You can find these in the going_modular folder on the course GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "508385cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 225\n",
      "    Root location: .data/pizza_steak_sushi/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=None)\n",
      "               ToTensor()\n",
      "           )\n",
      "Test data:\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 75\n",
      "    Root location: .data/pizza_steak_sushi/test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=None)\n",
      "               ToTensor()\n",
      "           )\n",
      "--------------------- Hyperparameters ---------------------\n",
      "Data path:       .data          | Batch size:      32             \n",
      "Learning rate:   0.001          | Number of epochs:5              \n",
      "Hidden units:    10             \n",
      "-----------------------------------------------------------\n",
      "-------------- Epoch 0 --------------\n",
      "Train metrics: (1.0981, 0.30)\n",
      "Test metrics: (1.0961, 0.27)\n",
      "-------------- Epoch 1 --------------\n",
      "Train metrics: (1.0990, 0.31)\n",
      "Test metrics: (1.0974, 0.26)\n",
      "-------------- Epoch 2 --------------\n",
      "Train metrics: (1.0978, 0.30)\n",
      "Test metrics: (1.0959, 0.38)\n",
      "-------------- Epoch 3 --------------\n",
      "Train metrics: (1.0996, 0.34)\n",
      "Test metrics: (1.0972, 0.32)\n",
      "-------------- Epoch 4 --------------\n",
      "Train metrics: (1.0978, 0.34)\n",
      "Test metrics: (1.0957, 0.54)\n",
      "-------------------------------------\n",
      "[INFO]: Training time: 4.195\n",
      "'models' already exists, skipping this step.\n",
      "[INFO]: Saving model to: models/0.5_going_modular_script_mode_TinyVGG.pth\n"
     ]
    }
   ],
   "source": [
    "!python going_modular/train.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "000974dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/train.py\n",
    "\n",
    "'''\n",
    "Trains a PyTorch image classification model using device-agnostic code.\n",
    "''' \n",
    "\n",
    "import os \n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import data_setup, engine, model_builder, utils\n",
    "from timeit import default_timer as timer\n",
    "from utils import fit_text\n",
    "import argparse\n",
    "\n",
    "# Getting arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "\n",
    "data_group= parser.add_argument_group(\"Data\")\n",
    "data_group.add_argument(\"--data_path\", type=str, default=\".data\", metavar=\"DIR\",\n",
    "                    help=\"Path where data is stored. (type: %(type)s, default: %(default)s)\")\n",
    "data_group.add_argument(\"--batch_size\", type=int, default=32, metavar=\"BATCH\",\n",
    "                    help=\"Size of each batch in the dataloder. (type: %(type)s, default: %(default)s)\")\n",
    "\n",
    "train_group = parser.add_argument_group(\"Training\")\n",
    "train_group.add_argument(\"--epochs\", type=int, default=5, metavar=\"EPOCHS\",\n",
    "                    help=\"Number of epochs to train the model. (type: %(type)s, default: %(default)s)\")\n",
    "train_group.add_argument(\"--learning_rate\", type=float, default=0.001, metavar=\"LR\",\n",
    "                    help=\"Optimizer's learning rate. (type: %(type)s, default: %(default)s)\")\n",
    "\n",
    "model_group = parser.add_argument_group(\"Model\")\n",
    "model_group.add_argument(\"--hidden_units\", type=int, default=10, metavar=\"H_UNITS\",\n",
    "                    help=\"Number of hidden units in the neural network. (type: %(type)s, default: %(default)s)\")\n",
    "\n",
    "options = parser.parse_args()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Setup hyperparameters\n",
    "NUM_EPOCHS = options.epochs\n",
    "BATCH_SIZE = options.batch_size\n",
    "HIDDEN_UNITS = options.hidden_units\n",
    "LEARNING_RATE = options.learning_rate\n",
    "DATA_PATH = options.data_path\n",
    "\n",
    "# Setup directories \n",
    "train_dir = DATA_PATH+\"/pizza_steak_sushi/train\"\n",
    "test_dir = DATA_PATH+\"/pizza_steak_sushi/test\"\n",
    "\n",
    "# Device agnostic-code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Create transforms\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Dataloders & class names \n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                  test_dir=test_dir,\n",
    "                                                                  transform=data_transform,\n",
    "                                                                  batch_size=BATCH_SIZE)\n",
    "# Create the model\n",
    "model = model_builder.TinyVGG(in_c=3,\n",
    "                              out_shape=len(class_names),\n",
    "                              hidden_units=HIDDEN_UNITS).to(device)\n",
    "\n",
    "# Setup loss & optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(params=model.parameters(),\n",
    "                        lr=LEARNING_RATE)\n",
    "\n",
    "# Print out hyperparameters\n",
    "print(\"--------------------- Hyperparameters ---------------------\")\n",
    "print(f\"{'Data path:':<17}{fit_text(DATA_PATH,15)}| {'Batch size:':<17}{fit_text(BATCH_SIZE,15)}\")\n",
    "print(f\"{'Learning rate:':<17}{fit_text(LEARNING_RATE,15)}| {'Number of epochs:':<17}{fit_text(NUM_EPOCHS,15)}\")\n",
    "print(f\"{'Hidden units:':<17}{fit_text(HIDDEN_UNITS,15)}\")\n",
    "print(\"-----------------------------------------------------------\")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "start_t = timer()\n",
    "results = engine.train(model=model,\n",
    "                       loss_fn=loss_fn,\n",
    "                       optimizer=optim,\n",
    "                       train_dataloader=train_dataloader,\n",
    "                       test_dataloader=test_dataloader,\n",
    "                       epochs=NUM_EPOCHS,\n",
    "                       dev=device)\n",
    "end_t = timer()\n",
    "print(f\"[INFO]: Training time: {end_t-start_t:.3f}\")\n",
    "\n",
    "# Save the model\n",
    "utils.save_model(model=model,\n",
    "                 target_dir=\"models\",\n",
    "                 model_name=\"0.5_going_modular_script_mode_TinyVGG.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fe85f8",
   "metadata": {},
   "source": [
    "#### 3. Create a script to predict (such as predict.py) on a target image given a file path with a saved model.\n",
    "* For example, you should be able to run the command python predict.py some_image.jpeg and have a trained PyTorch model predict on the image and return its prediction.\n",
    "* To see example prediction code, check out the predicting on a custom image section in notebook 04.\n",
    "* You may also have to write code to load in a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd7d2fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists, skipping this step.\n",
      "Downloading image at: '.data/custom_image.jpg'...\n"
     ]
    }
   ],
   "source": [
    "# Downloading the image\n",
    "from pathlib import Path\n",
    "import requests as rq\n",
    "\n",
    "data_path = Path(\".data\")\n",
    "if not data_path.exists():\n",
    "    print(f\"Creating data directory as: '{data_path}'...\")\n",
    "    data_path.mkdir()\n",
    "else:\n",
    "    print(f\"Directory already exists, skipping this step.\")\n",
    "    \n",
    "custom_image_path = data_path/\"custom_image.jpg\"\n",
    "if not custom_image_path.exists():\n",
    "    print(f\"Downloading image at: '{custom_image_path}'...\")\n",
    "    url = \"https://imgs.search.brave.com/3Ul7nnUJ3C532AlLy9D_RXR98XL4CRDzLN0gFf_Y-x8/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly9saDUu/Z29vZ2xldXNlcmNv/bnRlbnQuY29tL3Av/QUYxUWlwTkpmRUFx/a3hnVGZqektTZUwt/ekRGc0Q2VFBKWVYz/bjA0VVRCeUk9dzgw/MC1oNTAwLWstbm8\"\n",
    "    request = rq.get(url=url)\n",
    "    with open(custom_image_path, \"wb\") as f:\n",
    "        f.write(request.content)\n",
    "else:\n",
    "    print(f\"Image already downladed, skipping this step.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "de958935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/predict.py \n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import argparse \n",
    "import torch\n",
    "from model_builder import TinyVGG\n",
    "from utils import fit_text\n",
    "\n",
    "dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"image_path\", metavar=\"IMG\", type=str,\n",
    "                    help=\"Path to the image for which the prediction is desired.\")\n",
    "parser.add_argument(\"--model_path\", metavar=\"MODEL\", type=str ,\n",
    "                    default=\"./models/0.5_going_modular_script_mode_TinyVGG.pth\",\n",
    "                    help=\"Path to the model that will make the inference.\")\n",
    "parser.add_argument(\"--hidden_units\", metavar=\"UNITS\", default=10, type=int,\n",
    "                    help=\"Number of hidden units used in the model.\")\n",
    "parser.add_argument(\"image_class\", metavar=\"CLASS\", type=str,\n",
    "                    help=\"Image class, it must be one between: [pizza, steak, sushi].\")\n",
    "\n",
    "options = parser.parse_args()\n",
    "HIDDEN_UNITS = options.hidden_units\n",
    "MODEL_PATH = options.model_path\n",
    "IMAGE_PATH = options.image_path\n",
    "IMAGE_CLASS = options.image_class\n",
    "\n",
    "# Print out options\n",
    "print(\"--------------------- Hyperparameters ---------------------\")\n",
    "print(f\"{'Image path:':<17}{fit_text(IMAGE_PATH,15)}| {'Model path:':<17}{fit_text(MODEL_PATH,15)}\")\n",
    "print(f\"{'Hidden units:':<17}{fit_text(HIDDEN_UNITS,15)}| {'Class:':<17}{fit_text(IMAGE_CLASS,15)}\")\n",
    "print(\"-----------------------------------------------------------\")\n",
    "\n",
    "\n",
    "################# Getting the image #################model_builder i\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "])\n",
    "image = transform(read_image(IMAGE_PATH).type(dtype=torch.float32).to(dev)/255)\n",
    "\n",
    "################# Getting the model #################\n",
    "loaded__model = TinyVGG(in_c=3,\n",
    "                        out_shape=3,\n",
    "                        hidden_units=HIDDEN_UNITS)\n",
    "state_dict = torch.load(MODEL_PATH)\n",
    "loaded__model.load_state_dict(state_dict)\n",
    "\n",
    "################# Making the prediction #################\n",
    "class_names = [\"pizza\", \"steak\", \"sushi\"]\n",
    "real_label = [IMAGE_CLASS]\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "with torch.inference_mode():\n",
    "    loaded__model.eval()\n",
    "    logits = loaded__model(image.unsqueeze(dim=0))\n",
    "    pred = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "################# Printing out #################\n",
    "print(f\"Real class: {IMAGE_CLASS} | Prediction: {class_names[pred]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "046c269f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- Hyperparameters ---------------------\n",
      "Image path:      .data/custom...| Model path:      ./models/0.5...\n",
      "Hidden units:    20             | Class:           sushi          \n",
      "-----------------------------------------------------------\n",
      "Image shape: torch.Size([3, 64, 64])\n",
      "Real class: sushi | Prediction: sushi\n"
     ]
    }
   ],
   "source": [
    "!python going_modular/predict.py --hidden_units 20 .data/custom_image.jpg sushi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b0cdfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: predict.py [-h] [--model_path MODEL] [--hidden_units UNITS] IMG CLASS\n",
      "\n",
      "positional arguments:\n",
      "  IMG                   Path to the image for which the prediction is desired.\n",
      "  CLASS                 Image class, it must be one between: [pizza, steak,\n",
      "                        sushi].\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --model_path MODEL    Path to the model that will make the inference.\n",
      "  --hidden_units UNITS  Number of hidden units used in the model.\n"
     ]
    }
   ],
   "source": [
    "!python going_modular/predict.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f397f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch.env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
